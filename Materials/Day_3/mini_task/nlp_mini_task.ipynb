{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Mini Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Ties de Kok ([Personal Website](http://www.tiesdekok.com))  \n",
    "**Last updated:** 15 May 2018  \n",
    "**Python version:** Python 3.6  \n",
    "**License:** MIT License  \n",
    "**Credit:** part of these tasks were co-created by Stephan Hollander ([Personal Website](https://www.tilburguniversity.edu/webwijs/show/s.hollander/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Introduction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will provide you with \"tasks\" that you can try to solve.  \n",
    "\n",
    "Most of what you need is discussed in the tutorial notebooks, the rest you will have to Google (which is an important exercise in itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Relevant notebooks*\n",
    "\n",
    "1) [`0_python_basics.ipynb`](https://nbviewer.jupyter.org/github/TiesdeKok/LearnPythonforResearch/blob/master/0_python_basics.ipynb)  \n",
    "\n",
    "\n",
    "2) [`2_handling_data.ipynb`](https://nbviewer.jupyter.org/github/TiesdeKok/LearnPythonforResearch/blob/master/2_handling_data.ipynb)  \n",
    "\n",
    "\n",
    "3) [`NLP_Notebook.ipynb`](https://nbviewer.jupyter.org/github/TiesdeKok/Python_NLP_Tutorial/blob/master/NLP_Notebook.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Mini Task <br> --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this mini-task is to get hands-on experience with handling, cleaning, and analyzing textual data using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "\n",
    "There are two primary tasks and one challenging bonus task:\n",
    "\n",
    "**Task 1)** Following Garcia and Norli (2012), extract state name counts from MD&As to assess geographic dispersion  \n",
    "\n",
    "**Task 2)** Create a sentiment score for MD&As based on the Loughran and McDonald (2011) word lists  \n",
    "\n",
    "---------------------------------------------------\n",
    "\n",
    "**Bonus task 3)** Combine task 1 and 2, evaluate the sentiment score relating to state name references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References  \n",
    "\n",
    "Garcia, D., & Norli, Ø. (2012). Geographic dispersion and stock returns. Journal of Financial Economics, 106(3), 547-565.  \n",
    "Loughran, T., & McDonald, B. (2011). When is a liability not a liability? Textual analysis, dictionaries, and 10‐Ks. The Journal of Finance, 66(1), 35-65."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering and extracting the MD&A section of a 10-K is quite tricky.  \n",
    "\n",
    "I have therefore included a random selection of 20 pre-processed MDA filings.  \n",
    "\n",
    "In the \"data\" folder you will find a folder called \"MDA_files\". Each file in this folder is an MD&A filing, the filename is the unique identifier.\n",
    "\n",
    "You will also find a file called `MDA_META_DF.xlsx` in the \"data\" folder, this contains the following meta-data for eaching MD&A: (filing date, cik, company name, and link to filing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files should all be in the following folder:  \n",
    "```\n",
    "join('data', 'MDA_files')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Pre-process text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might need to split it into sentences, maybe split it into words, maybe remove invalid characters.\n",
    "\n",
    "Whatever you see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Extract state name counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow Garcia and Norli (2012) and count the number of times that each U.S. state name is mentioned in the MD&A.  \n",
    "\n",
    "Then:\n",
    "\n",
    "1. Create a DataFrame for each MD&A that shows the number of times each U.S. state name is mentioned.  \n",
    "2. Create a DataFrame to report the min, max, mean, median, and stdev for the number of times that each state is mentioned in MD&As. \n",
    "\n",
    "**Note:** state names are provided in the `state_names.xlsx` file in the \"data\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Create sentiment score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow Loughran and McDonald (2011) and count the number of times a tone word from their dictionary is mentioned.  \n",
    "\n",
    "Then:  \n",
    "\n",
    "1. For each MD&A calculate the total number of negative and total number of positive words mentioned.   \n",
    "2. Tabulate these total counts in a DataFrame together with the total number of words in the MD&A.  \n",
    "3. Create a new column which calculates a sentiment score using the following equation:  \n",
    "\n",
    "$$\\frac{(Num\\ Positive\\ Words - Num\\ Negative\\ Words)}{Total\\ Number\\ of\\ Words}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 1:** You can split a sentence into words using any of the tokenizers mentioned in the NLP notebook.  \n",
    "**Note 2:** The Loughran and McDonald dictionary is included in the \"data\" folder: `LoughranMcDonald_MasterDictionary_2014.xlsx `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task 3: Sentiment score relating to state name references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of tone words used within a +/- 250 character range for a U.S. state name.\n",
    "\n",
    "Then:\n",
    "\n",
    "1. Create a DataFrame for each MD&A where you report the total number of positive and total number of negative words by U.S. state name.  \n",
    "2. Create aggregate descriptives for the States with the most positive words and the States with most negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
